# 科技大数据简易搜索引擎-后端

## 简介

* **功能**：基于知识图谱与贝叶斯分类器的科技大数据搜索引擎
* **架构**：
  * 框架与工具
    * 后端：[SpringBoot](https://spring.io/projects/spring-boot/)
    * 图谱：[neo4j](https://spring.io/projects/spring-data-neo4j)
    * 分词：[hanlp](https://github.com/hankcs/HanLP)
    * 分类器：`solr` 的朴素贝叶斯分类器 `NaiveBayesModel`
* **分类方法参考**：[基于电影知识图谱的智能问答系统 - by appleyk](https://blog.csdn.net/Appleyk/article/details/80422055?tdsourcetag=s_pctim_aiomsg)， 在原基础上有较大改进，大幅度提高分类器性能

## Neo4j 图数据库查询

* **接口一览**
  * 查询**专家**
    * 通过专家名查询专家信息
    * 通过专家 code 专家号码，返回专家信息
    * 通过论文 paperId 查询专家信息
    * 通过单位名称获取专家信息
    * 通过给定论文所属的领域，查询专家信息，支持模糊查询
    * 通过给定论文所属的领域，查询专家信息，支持模糊查询
  * 查询**期刊**
    * 通过期刊名称 journalName 查询期刊信息
    * 通过期刊的质量等级 journalQuality 查询期刊的信息
  * 查询**论文**
    * 通过论文名模糊查找论文
    * 通过 作者code 查找论文，因为作者可能会重名，所以不用作者名字查找
    * 通过论文 paper_id 查询论文信息
    * 通过论文 keywords 查询论文信息
    * 通过论文 year 来查询论文信息
    * 通过论文发表 areaCode 来查询论文信息
    * 通过论文的 abstract 摘要来查询论文信息
    * 通过专家姓名返回论文的信息
    * 通过 专家 1 姓名 和 专家 2 姓名，查询论文
    * 通过单位名称获取某单位拥有哪些论文/专利
    * 通过专家姓名和论文关键字查询论文信息
  * 查询**单位**
    * 通过 单位/机构名 返回 UnitNode
* 实现细节
  * 实体关系定义：使用 `@NodeEntity` 注解定义 `neo4j` 节点实体，并在实体类中用 `@Relationship` 注解定义实体相关的关系
  * 查询：继承 `Neo4jRepository` 接口，简单查询使用 `Java` 原生查询，复杂查询使用 `Cypher`

## 智能问答

* 分类原理简介

  * 基于 `hanlp` 与 贝叶斯分类器的模板匹配方式，增添了关键 词性惩罚机制

* 分类原理详解

  * **训练流程**

    * 准备一个问题集，如本项目准备了7类问题，每类问题若干个不同问法(filter后面会有详解)

    ```json
    {
      "comments": "HanLP 的人名的 词性标注为 nr ",
      "questionDescription": "某人发表了哪些论文",
      "questionType": 0,
      "filter":
        {
          "mustContain":["nr"]
        ,
          "canNotContain":["unit", "n2r"]
        }
      ,
      "questions": [
        {
          "id": 1,
          "value": "nr发表了哪些论文"
        },
        {
          "id": 2,
          "value": "nr发布了哪些论文"
        },
        {
          "id": 3,
          "value": "nr写了哪些论文"
        },
        {
          "id": 4,
          "value": "nr创作了哪些论文"
        },
        {
          "id": 5,
          "value": "nr有哪些论文"
        },
        {
          "id": 6,
          "value": "nr有哪些论文"
        },
        {
          "id": 7,
          "value": "nr持有哪些专利"
        },
        {
          "id": 8,
          "value": "nr发布了哪些专利"
        },
        {
          "id": 9,
          "value": "nr发明了哪些专利"
        },
        {
          "id": 10,
          "value": "nr申请哪些专利"
        },
        {
          "id": 11,
          "value": "nr有哪些专利"
        },
        {
          "id": 12,
          "value": "有哪些论文是nr写的"
        }
      ]
    }
    ```

    

    * 创建单词集`vocabulary.txt` 将问题中包含的 **非实体短语** 全都放进去，如 "写的", "谁", "单位"

    * 使用 `hanlp` 的分词器将每个问题都分词，并将分词得到的短语与单词集中的短语进行匹配，导入贝叶斯分类器（贝叶斯分类器全是0,1向量）。

      * 举例：

        
        1. 问题类：某某发表了哪些论文
        2. 先训练第一个小问题："张三发表了什么论文"
        3. 分词结果："张三"（实体词暂不考虑), "发表", "了"，"什么", "论文"
        4. 若单词集长度为200，则构建一个[0,0,0..0,0]的长度为200的向量
        5. 命中单词为"发表", "了"，"什么", 将向量中的相应的位置改为 1
        6. 送入贝叶斯分类器进行训练
        7. 训练其余的子问题和问题类
    
  * **预测流程**
  
    * 将待预测问题利用 `hanlp` 分词
    * 抽取实体，将实体替换为抽象的词性，得到新问题。同时将实体保存到字典中，传给查询层。如"张三发表了什么论文"，替换为，"nr 发表 了 什么 论文"(nr表示人名词性)，并将"张三"传给查询层。
    * 与单词集进行命中匹配，即将待预测问题转化成0,1向量
    * 将获得的向量交给贝叶斯分类器进行预测，得到一个可能性数组，即该问题在每个分类下的得分情况，得分越高，是该问题类的可能性就越大，取得分最高的即可
    * 查询层得到问题的种类与实体，按照既定的问题模板查询
  
  * **预测改进**
  
    * **原分类器局限性分析**
      * 上面的预测流程即参考博客的分类方式，但是当分类较多的时候效果很差。原因如下
      * 原分类方法忽略了实体的影响，仅仅利用 非实体 短语进行分类与预测
      * 例如：张三发表了什么论文；张三和李四发表了什么论文
      * 这两个问题原分类器只利用了"和"，“发表”，”了“，”什么“，”论文“这几个短语
      * 完全忽略了”张三“，”李四“这两个实体
      * 所以这两个问题在分类器看来几乎没区别，无法区分这两个问题
    * **分类器改进难点**
      * 单词集的单词是固定有限的
      * 实体的个数是无限的，如“张三”，“李四”
      * 所以无法通过贝叶斯的命中方式提高精度
    * **详细改进策略**
      * **思路：既然无法在分类时利用不同问题实体的差异性，那么可以在分类后对结果进行再处理，即利用实体惩罚问题在各个分类上的得分**
      * 原理详解
        * 如果具体问题是“张三发表了哪些论文”，那么这个问题在“某某发表了什么论文”和“某某1和某某2发表了什么论文”两个分类上的得分几乎一样
        * 但是两种的实体完全不一样，一个有一个人名，一个有两个人名
        * 可以利用这一点惩罚（修改）分类得分
        * 如“某某1和某某2发表了什么论文”这个问题类，待预测问题只有一个人名或无人名，就将带预测问题在这个问题类上的得分降低
        * 归纳一下便是：**在分类之后的得分基础上，对于每个问题，都定义这个问题必须包含哪些实体以及一定不能包含哪些实体，如果不满足就进行惩罚**（即前面问题训练中定义的 `filter`）
    * **改进后分类效果**
      * 成功率极高，已有问题类为100%